# ğŸ©º COVID-19 Chest X-Ray Captioning Project

This project is for our machine learning course final project, due **April 27**. We aim to develop a CNN+RNN model that generates short, interpretable captions for chest X-ray images, identifying whether they are normal or show signs of pneumonia (COVID-related).

---

## ğŸ¯ Project Goals

- Convert chest X-ray classification into a **captioning task**
- Use a **CNN encoder** (e.g., ResNet) to extract image features
- Use an **RNN decoder** (e.g., LSTM) to generate medical-style captions
- (Bonus) Add a **self-refinement loop**: the model revises its own caption based on its first output
- Explore **evaluation metrics**, **visualizations**, and **model comparisons** to demonstrate learning

---

## ğŸ“… Important Dates

- **Project Due**: April 27  
- **Penalty**: 20% per day late (No grade if more than 5 days late)
- **Final Deliverable**: PDF report + source code  
- Each member must **submit individually**

---

## ğŸ§  Project Structure

```
covid-detection/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/                  # Original dataset (downloaded via script)
â”‚       â”œâ”€â”€ Chest_xray_Corona_Metadata.csv  # Original metadata
â”‚       â”œâ”€â”€ Chest_xray_Corona_dataset_Summary.csv  # Dataset summary
â”‚       â””â”€â”€ Coronahack-Chest-XRay-Dataset/
â”‚           â””â”€â”€ Coronahack-Chest-XRay-Dataset/
â”‚               â”œâ”€â”€ image_captions.csv  # Generated captions for training
â”‚               â”œâ”€â”€ train/              # Training images
â”‚               â””â”€â”€ test/               # Testing images
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ collate.py            # Collates data for model training
â”‚   â”œâ”€â”€ dataset.py            # Dataset class for PyTorch
â”‚   â”œâ”€â”€ download_data.py      # Downloads dataset from Kaggle
â”‚   â”œâ”€â”€ evaluate.py           # Model evaluation
â”‚   â”œâ”€â”€ model.py              # CNN+RNN model definitions
â”‚   â”œâ”€â”€ predict.py            # Generate predictions
â”‚   â”œâ”€â”€ preprocess_and_caption.py  # Processes images and generates captions
â”‚   â”œâ”€â”€ test_imports.py       # Sanity check for module imports
â”‚   â””â”€â”€ train.py              # Model training
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ paths.py              # Shared paths for the project
â”‚   â””â”€â”€ tokenizer.py          # Text tokenization utilities
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ dataset_exploration.ipynb  # Initial EDA and dataset analysis
â”‚   â””â”€â”€ preprocess_and_caption_updated.ipynb  # Caption generation development
â”œâ”€â”€ run_workflow.sh           # Main workflow script
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â””â”€â”€ .venv/
```

---

## ğŸ› ï¸ Environment Setup

We use Python `venv` and [`uv`](https://github.com/astral-sh/uv) for dependency management.

### Setup Steps

1. Clone the repository  
2. Create and activate a virtual environment:
   ```bash
   uv venv -p 3.9
   source .venv/bin/activate  # macOS/Linux
   ```
3. Install dependencies:
   ```bash
   uv pip install -r requirements.txt
   ```

---

## ğŸ“¥ Download the Dataset

We use the [CoronaHack Chest X-ray Dataset](https://www.kaggle.com/datasets/praveengovi/coronahack-chest-xraydataset).

To download:

1. Place your `kaggle.json` API key in `~/.kaggle/`  (check https://www.kaggle.com/docs/api#authentication for Windows instructions)
2. Run the script:
   ```bash
   python -m scripts.download_data
   ```

This will download and extract the dataset to `data/raw/`.

---

## ğŸ”„ Running the Workflow

We've created a workflow script to handle the entire pipeline. Run:

```bash
./run_workflow.sh
```

### Available Options

- `--no-download`: Skip dataset download (use if already downloaded)
- `--no-captions`: Skip caption generation step
- `--no-train`: Skip model training
- `--evaluate`: Run model evaluation

Example:
```bash
./run_workflow.sh --no-download --evaluate
```

---

## ğŸ“Š Dataset Overview

The dataset contains chest X-ray images categorized as:
- Normal (1,576 images)
- Pneumonia (4,334 images)
  - Bacterial pneumonia (2,777 images)
  - Viral pneumonia (1,493 images)
  - COVID-19 (58 images)
  - Other viral types (11 images)

Our preprocessing generates medical-style captions for each image based on these classifications:

| Classification | Generated Caption |
|----------------|------------------|
| Normal | "No signs of pneumonia." |
| Bacterial Pneumonia | "Pneumonia likely due to bacterial infection." |
| Viral Pneumonia | "Pneumonia likely due to viral infection." |
| COVID-19 | "Lung opacity consistent with COVID-19." |
| Other Viral | "Signs of pneumonia, likely viral origin." |

---

## ğŸ““ Notebooks

### Dataset Exploration
The [dataset_exploration.ipynb](notebooks/dataset_exploration.ipynb) notebook provides:
- Analysis of the dataset structure and metadata
- Handling of missing values and duplicates
- Visualization of label distributions

### Caption Generation
The [preprocess_and_caption_updated.ipynb](notebooks/preprocess_and_caption_updated.ipynb) notebook:
- Loads and cleans the metadata
- Implements rule-based caption generation
- Creates and saves image paths and their associated captions for training

---

## ğŸ“š Report Requirements

Our final report will follow the ACM SIG format and include:

- Group members & contributions
- Introduction and problem statement
- Literature review (3+ papers)
- ML models, methods, training
- Results and evaluation
- Conclusion and contributions

---

## ğŸ‘¥ Team Members

- Wyatt Lamberth  
- Gabriel Zermeno
- Tien Phu Tran

---

## ğŸ“ Notes

- Use `python -m` to run scripts inside the project structure (e.g., `python -m scripts.download_data`)
- All paths are managed in `utils/paths.py` for consistency across notebooks and scripts
- Caption generation is rule-based, creating descriptive text for each chest X-ray based on its metadata
- The preprocessing pipeline handles image loading, validation, and caption generation